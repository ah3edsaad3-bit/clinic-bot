from flask import Flask, request
import requests
from openai import OpenAI
import time
import os
import threading

app = Flask(__name__)

# Tokens from Environment Variables
VERIFY_TOKEN = "goldenline_secret"
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)

# Sessions memory
SESSIONS = {}
BUFFER_DELAY = 15  # 15 seconds Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙÙŠ Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ø­Ø¯Ø©
MAX_HISTORY_TURNS = 10 # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¯ÙˆØ§Ø± (user/assistant) Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡Ø§ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©


def schedule_reply(user_id):
    """Wait 15 seconds â€” if no new messages, process."""
    time.sleep(BUFFER_DELAY)

    state = SESSIONS.get(user_id)
    if state is None:
        return

    now = time.time()

    # If no new messages in last 15 sec â†’ process
    if (now - state["last_message_time"]) >= BUFFER_DELAY:
        
        # 1. Prepare user message and add to history
        messages_buffer = state["messages"] 
        
        if not messages_buffer:
            return

        final_user_text = " ".join(messages_buffer)

        # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù€ history Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        state["history"].append({"role": "user", "content": final_user_text})

        # 2. Call OpenAI with the full history
        reply = ""
        try:
            # ØªÙ…Ø±ÙŠØ± Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (history) Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚
            reply = ask_openai(state["history"]) 
            
            # 3. Append assistant's reply to history
            state["history"].append({"role": "assistant", "content": reply})
            
        except Exception as e:
            print("âŒ OpenAI Error:", e)
            reply = "ØµØ§Ø± Ø®Ù„Ù„ Ø¨Ø³ÙŠØ·ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© ğŸ™"
            
            # Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø®Ø·Ø£ØŒ Ù†Ø­Ø°Ù Ø¢Ø®Ø± Ø±Ø³Ø§Ù„Ø© Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø¶ÙÙ†Ø§Ù‡Ø§ Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø³ÙŠØ§Ù‚ Ø®Ø§Ø·Ø¦
            state["history"].pop()

        send_message(user_id, reply)

        # 4. Truncate history to prevent large context window (and high cost)
        if len(state["history"]) > MAX_HISTORY_TURNS:
            # Ù†Ø­ØªÙØ¸ Ø¨Ø¢Ø®Ø± MAX_HISTORY_TURNS ÙÙ‚Ø·
            state["history"] = state["history"][-MAX_HISTORY_TURNS:]
        
        # 5. Reset the temporary buffer only, KEEPING the conversation history
        SESSIONS[user_id]["messages"] = []
        SESSIONS[user_id]["last_message_time"] = 0


def add_user_message(user_id, text):
    now = time.time()

    if user_id not in SESSIONS:
        # Initializing the session with 'history' list for context memory
        SESSIONS[user_id] = {
            "messages": [], 
            "history": [], # Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
            "last_message_time": now
        }

    SESSIONS[user_id]["messages"].append(text)
    SESSIONS[user_id]["last_message_time"] = now

    # Start timer thread
    t = threading.Thread(target=schedule_reply, args=(user_id,))
    t.start()


def ask_openai(conversation_history):
    system_prompt = (
        "Ø§Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ØªØ±Ø¯ Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠØ© ÙˆØ¨Ø§Ø®ØªØµØ§Ø±ØŒ "
        "ÙˆØ¥Ø°Ø§ Ø§Ù„Ø²Ø¨ÙˆÙ† ÙŠØ±ÙŠØ¯ ÙŠØ­Ø¬Ø² Ø§Ø·Ù„Ø¨ Ø§Ù„Ø§Ø³Ù… ÙˆØ§Ù„Ø±Ù‚Ù…."
    )
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù€ system prompt Ù…Ø¹ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    messages_with_system = [{"role": "system", "content": system_prompt}] + conversation_history

    rsp = client.chat.completions.create(
        model="gpt-4o-mini", # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯ Ù„Ø¯Ø¹Ù… Ø£ÙØ¶Ù„
        messages=messages_with_system,
        max_tokens=200
    )

    return rsp.choices[0].message.content.strip()


@app.route("/", methods=["GET"])
def home():
    return "Render bot running with 15s buffer â³"


@app.route("/webhook", methods=["GET"])
def verify():
    mode = request.args.get("hub.mode")
    token = request.args.get("hub.verify_token")
    challenge = request.args.get("hub.challenge")

    if mode == "subscribe" and token == VERIFY_TOKEN:
        return challenge, 200

    return "Error", 403


@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.get_json()
    print("ğŸ“© Incoming:", data)

    for entry in data.get("entry", []):
        for ev in entry.get("messaging", []):
            sender = ev["sender"]["id"]

            if "message" in ev and "text" in ev["message"]:
                text = ev["message"]["text"]

                add_user_message(sender, text)

    return "OK", 200


def send_message(receiver, text):
    url = "https://graph.facebook.com/v18.0/me/messages"
    params = {"access_token": PAGE_ACCESS_TOKEN}
    payload = {
        "recipient": {"id": receiver},
        "message": {"text": text}
    }
    requests.post(url, params=params, json=payload)


# Render server
if __name__ == "__main__":
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù†ÙØ° 10000 Ù‡Ùˆ Ø§Ù„Ù…Ù†ÙØ° Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Render Ø£Ùˆ Ù…Ù†ØµØ© Ø§Ù„Ø§Ø³ØªØ¶Ø§ÙØ©
    app.run(host="0.0.0.0", port=10000)
