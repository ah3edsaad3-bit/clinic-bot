from flask import Flask, request
import requests
from openai import OpenAI
import time
import os
import threading

app = Flask(__name__)

# Tokens from Environment Variables
VERIFY_TOKEN = "goldenline_secret"
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)

# Sessions memory
SESSIONS = {}  # { user_id: {"messages": [...], "last_message_time": time } }
BUFFER_DELAY = 15        # ููุช ุชุฌููุน ุงูุฑุณุงุฆู
MEMORY_TIMEOUT = 900     # 15 ุฏูููุฉ ุฐุงูุฑุฉ = 900 ุซุงููุฉ


# ---------------------------------------------------------
# 1) 15-second buffer for merging messages
# ---------------------------------------------------------

def schedule_reply(user_id):
    """ููุชุธุฑ 15 ุซุงููุฉุ ุฅุฐุง ูุง ูุตูุช ุฑุณุงูุฉ ุฌุฏูุฏุฉ โ ูุฌุงูุจ."""
    time.sleep(BUFFER_DELAY)

    state = SESSIONS.get(user_id)
    if state is None:
        return

    now = time.time()

    # ุฅุฐุง ูุงูู ุฑุณุงูุฉ ุฌุฏูุฏุฉ ุฎูุงู 15 ุซุงููุฉ โ ูุนุงูุฌ ุงูุฑุณุงุฆู
    if (now - state["last_message_time"]) >= BUFFER_DELAY:
        combined_text = " ".join(state["messages"])

        try:
            reply = ask_openai(user_id, combined_text)
        except Exception as e:
            print("โ OpenAI Error:", e)
            reply = "ุตุงุฑ ุฎูู ุจุณูุทุ ุญุงูู ูุฑุฉ ุซุงููุฉ ๐"

        send_message(user_id, reply)

        # ูุง ููุณุญ ุงูุฐุงูุฑุฉ โ ูุฎูููุง ุฅูู ุฃู ุชูุฑ 15 ุฏูููุฉ ุจุฏูู ุฑุณุงุฆู
        # ุงูุชูุธูู ุฑุงุญ ูุตูุฑ ุชููุงุฆูุงู ุฏุงุฎู add_user_message()


# ---------------------------------------------------------
# 2) Add message + long-term 15 min memory
# ---------------------------------------------------------

def add_user_message(user_id, text):
    now = time.time()

    # ุฅุฐุง ุงููุณุชุฎุฏู ุฌุฏูุฏ ุฃู ุฐุงูุฑุชู ุงูุชูุช โ ุณูู ุฌูุณุฉ ุฌุฏูุฏุฉ
    if user_id not in SESSIONS or (now - SESSIONS[user_id]["last_message_time"] > MEMORY_TIMEOUT):
        SESSIONS[user_id] = {
            "messages": [],
            "last_message_time": now
        }

    # ุฅุถุงูุฉ ุงูุฑุณุงูุฉ ุงูุฌุฏูุฏุฉ ุฅูู ุงูุฐุงูุฑุฉ
    SESSIONS[user_id]["messages"].append(text)
    SESSIONS[user_id]["last_message_time"] = now

    # ุชุดุบูู ูุคูุช ุงูุฏูุฌ
    t = threading.Thread(target=schedule_reply, args=(user_id,))
    t.start()


# ---------------------------------------------------------
# 3) OpenAI handler (with full memory context)
# ---------------------------------------------------------

def ask_openai(user_id, new_text):
    # ุฌูุน ูู ุชุงุฑูุฎ ุงููุญุงุฏุซุฉ
    full_context = " | ".join(SESSIONS[user_id]["messages"])

    system_prompt = """
ูููุช ูุตุฏูุ ุงูููุงุญุธุฉ ุฌุฏุงู ุฏูููุฉ. ุงูุจูุช ูุงุฒู ูููู "ุจูุงุน" ุดุงุทุฑ ูู ูุฌุฑุฏ ูุฌูุจ ุขููุ ููุงุฒู ูุญุณุณ ุงูุฒุจูู ุฅูู ูุญุตู ูุฑุตุฉ.

ุนุฏูุชูู ุงูู "Prompt" ูุถูุชูู ููุฑุฉ ุฎุงุตุฉ (ุฐูุงุก ุงูุฑุฏ ุนูู ุงูุฎุตููุงุช) ุญุชู ูุฌุงูุจ ุจุฐูุงุก ูููุฑ ุงูููุถูุน ูููููุฉ ูุงูุฌูุฏุฉ ุจุฏู ูููุฉ "ูุง".

ุงูุณุฎ ูุฐุง ุงููุต ุงูุฌุฏูุฏ ูุงุณุชุจุฏู ุงููุฏูู ุจู:

ุงูุฏูุฑ ูุงูุดุฎุตูุฉ:
ุฃูุช "ุนูู"ุ ุงููุณุงุนุฏ ุงูุฐูู ูุนูุงุฏุฉ "ูููุฏู ูุงูู". ุฃุณููุจู: ุนุฑุงูู ุจุบุฏุงุฏูุ ุฐูู ุงุฌุชูุงุนูุงูุ ูุฎุชุตุฑุ ููููุน. ูุฏูู ุชุญููู ุงูุณุคุงู ุฅูู ุญุฌุฒ.

ููุงุนุฏ ุงูุฑุฏ ุงูุฐููุฉ (ููู ุฌุฏุงู):
ููููุน ุงูุฑูุถ ุงููุจุงุดุฑ: ุฅุฐุง ุณุฃู ุนู ุชุฎููุถ ุฃู ูุงู "ุบุงูู"ุ ุฅูุงู ุฃู ุชููู "ูุง ูุงูู" ุฃู "ุงูุณุนุฑ ุซุงุจุช".

ุณูุงุณุฉ ุงูุฅููุงุน: ุฌุงูุจ ุฏุงุฆูุงู ุจุฃู "ุงูุฃุณุนุงุฑ ุงูุญุงููุฉ ูู ุฃุณุนุงุฑ ุนุฑูุถ ูุชูุงูุณูุฉ ุฌุฏุงู" ูุงุฑุจุท ุงูุณุนุฑ ุจู (ุงูููุงุฏ ุงูุฃููุงููุฉ + ุงูุถูุงู ุงูุญูููู). ุญุณุณู ุฅูู ูุงุฎุฐ ุตููุฉ ููุชุงุฒุฉ.

ุนุฏู ุชูุฑุงุฑ ุงูุชุฑุญูุจ: ุงูุชุฑุญูุจ ูุฑุฉ ูุงุญุฏุฉ ููุทุ ุจุนุฏูุง ุงุฏุฎู ุจุงูุฌูุงุจ ููุฑุงู.

ุงูุงุฎุชุตุงุฑ: ุฌูุงุจู ุณุทุฑูู ุฃู ุซูุงุซุฉุ ูุงููู ููุงูู ุฏุงุฆูุงู ุจุณุคุงู ูููุฏ ููุญุฌุฒ (ูุซูุงู: "ุชุญุจ ูุญุฌุฒููุ").

ุณููุงุฑูู ุงูุญุฌุฒ:
ุนูุฏ ุทูุจ ุงูุญุฌุฒ: "ุชูุงู ุญุจูุจูุ ุญุชู ุฃูููู ุงูุญุฌุฒ ุฏุฒูู ุงุณูู ูุฑููู."

ุจุนุฏ ุงุณุชูุงู ุงูุฑูู ูุงูุงุณู (ุฑุฏ ูุงุญุฏ ููุท): "ุชุฃููุฏ ุงูุญุฌุฒ: ุงูุงุณู: ... ุงูุฑูู: ... ุงูุฎุฏูุฉ: ... ุฑุงุญ ูุชูุงุตู ููุงู ุฎูุงู ูุญุธุงุช."

ูุนูููุงุช ุงูุนูุงุฏุฉ:
ุงูุนููุงู: ุจุบุฏุงุฏ โ ุฒูููุฉ โ ุดุงุฑุน ุงูุฑุจูุนู ุงูุฎุฏูู โ ุฏุงุฎู ูุฑุงุฌ ูุฌูุน ุฅุณุทูุจูู.

ุงูุฏูุงู: ููููุงู 4 ุนุตุฑุงู - 9 ูุณุงุกู (ุงูุฌูุนุฉ ุนุทูุฉ).

ุงูุฃุณุนุงุฑ ูุงูุฎุฏูุงุช (ุฑุฏ ุจุฐูุงุก):
ุงูุชุบููู (ุฒุงุฑููู ุฃููุงูู - ุถูุงู ูุฏู ุงูุญูุงุฉ):

ูู ุฒุงุฑููู: 75,000 ุฏ.ุน (ุนุฑุถ ุฎุงุต).

ุฒุงุฑููู ูุฏูุฌ ุฃููุงูุณ: 100,000 ุฏ.ุน.

ุฒุงุฑููู 3D: 125,000 ุฏ.ุน.

ุงูุญุดูุงุช: ุชุฌููููุฉ (35,000)ุ ุฌุฐุฑ (125,000).

ุงูููุน: ุนุงุฏู (25,000)ุ ุฌุฑุงุญู (75,000).

ุฃูุซูุฉ ูุชุนูููู "ุฐูุงุก ุงูุฑุฏ":
ุงููุฑุงุฌุน: "ุฃูู ูุฌุงู ุจุงูุณุนุฑุ / ุดู ุบุงูู" ุนูู: "ูุง ุทูุจ ูุงู ุงูุฃุณุนุงุฑ ูู ุฃุณุนุงุฑ ุนุฑูุถ ุญุงููุงูุ ูุชูุงูุณูุฉ ุฌุฏุงู ูุฃู ููุงุฏูุง ุฃููุงููุฉ ูุนูููุง ุถูุงู ูุฏู ุงูุญูุงุฉ. ุตุฏููู ุงูุณุนุฑ ููุด ููุงุณุจ ููุงุจู ุงูุฌูุฏุฉ. ุฃุซุจุชูู ุญุฌุฒุ"

ุงููุฑุงุฌุน: "ุฃูู ุชุฎููุถุงุชุ" ุนูู: "ุญุงููุงู ุฃุญูุง ูุณููู ุนุฑูุถ ุฎุงุตุฉ ูุงูุฃุณุนุงุฑ ูุฎูุถุฉ ููุงุฑูุฉ ุจุงูุณูู ูุน ุงูุญูุงุธ ุนูู ุงูููุงุฏ ุงูุฃุตููุฉ ูุงูุถูุงู. ุชุญุจ ุชุณุชุบู ุงูุนุฑุถ ููุญุฌุฒูู ููุนุฏุ"

ุงููุฑุงุฌุน: "ุจูุด ุงูุชุบูููุ" ุนูู: "ูุณุชุฎุฏู ุฒุงุฑููู ุฃููุงูู ุจุถูุงู ูุฏู ุงูุญูุงุฉุ ูุณุนุฑู ุจุงูุนุฑุถ ุญุงููุงู 75 ุฃูู ููุท ููุณู. ุดุบู ูุจูุถ ุงููุฌู. ุฏุฒูู ุงุณูู ูุฑููู ููุญุฌุฒุ"
โช๏ธ ุฃุณููุจ ุงูุฑุฏ:
- ูุฎุชุตุฑ ุฌุฏูุง
- ูุจู
- ูุฎูู ุงูููู
- ูุดุฑุญ ุจุจุณุงุทุฉ
"""

    rsp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": full_context}
        ],
        max_tokens=250
    )

    return rsp.choices[0].message.content.strip()


# ---------------------------------------------------------
# 4) Webhook routes
# ---------------------------------------------------------

@app.route("/", methods=["GET"])
def home():
    return "GoldenLine bot running โ Memory 15 minutes + Buffer 15 seconds"


@app.route("/webhook", methods=["GET"])
def verify():
    mode = request.args.get("hub.mode")
    token = request.args.get("hub.verify_token")
    challenge = request.args.get("hub.challenge")

    if mode == "subscribe" and token == VERIFY_TOKEN:
        return challenge, 200

    return "Error", 403


@app.route("/webhook", methods=["POST"])
def webhook():
    data = request.get_json()
    print("๐ฉ Incoming:", data)

    for entry in data.get("entry", []):
        for ev in entry.get("messaging", []):
            sender = ev["sender"]["id"]

            if "message" in ev and "text" in ev["message"]:
                text = ev["message"]["text"]
                add_user_message(sender, text)

    return "OK", 200


# ---------------------------------------------------------
# 5) Send reply to Facebook
# ---------------------------------------------------------

def send_message(receiver, text):
    url = "https://graph.facebook.com/v18.0/me/messages"
    params = {"access_token": PAGE_ACCESS_TOKEN}
    payload = {
        "recipient": {"id": receiver},
        "message": {"text": text}
    }

    r = requests.post(url, params=params, json=payload)
    print("๐ค Facebook:", r.text)


# Render server
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)
